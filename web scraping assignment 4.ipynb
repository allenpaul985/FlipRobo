{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the required libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "from selenium.common.exceptions import NoSuchElementException   # importing Exemption\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", -1) #displays whole column value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"</td>\n",
       "      <td>Pinkfong Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>8.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>7.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>5.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"See You Again\"</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Uptown Funk\"</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Bath Song\"</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>4.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Gangnam Style\"</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Phonics Song with Two Words\"</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>3.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Sugar\"</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Sorry\"</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Dame Tu Cosita\"</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Thinking Out Loud\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Dark Horse\"</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Faded\"</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Shake It Off\"</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Wheels on the Bus\"</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>3.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Lean On\"</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Bailando\"</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Girls Like You\"</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Let Her Go\"</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Mi Gente\"</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>June 29, 2017</td>\n",
       "      <td>2.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Perfect\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Hello\"</td>\n",
       "      <td>Adele</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>2.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>2.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Axel F\"</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>2.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                         Name  \\\n",
       "0   1.   \"Baby Shark Dance\"                            \n",
       "1   2.   \"Despacito\"                                   \n",
       "2   3.   \"Johny Johny Yes Papa\"                        \n",
       "3   4.   \"Shape of You\"                                \n",
       "4   5.   \"See You Again\"                               \n",
       "5   6.   \"Masha and the Bear – Recipe for Disaster\"    \n",
       "6   7.   \"Uptown Funk\"                                 \n",
       "7   8.   \"Learning Colors – Colorful Eggs on a Farm\"   \n",
       "8   9.   \"Bath Song\"                                   \n",
       "9   10.  \"Gangnam Style\"                               \n",
       "10  11.  \"Phonics Song with Two Words\"                 \n",
       "11  12.  \"Sugar\"                                       \n",
       "12  13.  \"Sorry\"                                       \n",
       "13  14.  \"Dame Tu Cosita\"                              \n",
       "14  15.  \"Roar\"                                        \n",
       "15  16.  \"Counting Stars\"                              \n",
       "16  17.  \"Thinking Out Loud\"                           \n",
       "17  18.  \"Dark Horse\"                                  \n",
       "18  19.  \"Faded\"                                       \n",
       "19  20.  \"Shake It Off\"                                \n",
       "20  21.  \"Wheels on the Bus\"                           \n",
       "21  22.  \"Lean On\"                                     \n",
       "22  23.  \"Bailando\"                                    \n",
       "23  24.  \"Girls Like You\"                              \n",
       "24  25.  \"Let Her Go\"                                  \n",
       "25  26.  \"Mi Gente\"                                    \n",
       "26  27.  \"Perfect\"                                     \n",
       "27  28.  \"Hello\"                                       \n",
       "28  29.  \"Waka Waka (This Time for Africa)\"            \n",
       "29  30.  \"Axel F\"                                      \n",
       "\n",
       "                            Artist        Upload Date Views  \n",
       "0   Pinkfong Kids' Songs & Stories  June 17, 2016      8.71  \n",
       "1   Luis Fonsi                      January 12, 2017   7.38  \n",
       "2   LooLoo Kids                     October 8, 2016    5.41  \n",
       "3   Ed Sheeran                      January 30, 2017   5.34  \n",
       "4   Wiz Khalifa                     April 6, 2015      5.13  \n",
       "5   Get Movies                      January 31, 2012   4.44  \n",
       "6   Mark Ronson                     November 19, 2014  4.19  \n",
       "7   Miroshka TV                     February 27, 2018  4.12  \n",
       "8   Cocomelon – Nursery Rhymes      May 2, 2018        4.10  \n",
       "9   Psy                             July 15, 2012      4.08  \n",
       "10  ChuChu TV                       March 6, 2014      3.90  \n",
       "11  Maroon 5                        January 14, 2015   3.48  \n",
       "12  Justin Bieber                   October 22, 2015   3.44  \n",
       "13  El Chombo                       April 5, 2018      3.37  \n",
       "14  Katy Perry                      September 5, 2013  3.36  \n",
       "15  OneRepublic                     May 31, 2013       3.31  \n",
       "16  Ed Sheeran                      October 7, 2014    3.26  \n",
       "17  Katy Perry                      February 20, 2014  3.08  \n",
       "18  Alan Walker                     December 3, 2015   3.07  \n",
       "19  Taylor Swift                    August 18, 2014    3.06  \n",
       "20  Cocomelon – Nursery Rhymes      May 24, 2018       3.05  \n",
       "21  Major Lazer                     March 22, 2015     3.04  \n",
       "22  Enrique Iglesias                April 11, 2014     3.04  \n",
       "23  Maroon 5                        May 31, 2018       3.04  \n",
       "24  Passenger                       July 25, 2012      3.00  \n",
       "25  J Balvin                        June 29, 2017      2.92  \n",
       "26  Ed Sheeran                      November 9, 2017   2.86  \n",
       "27  Adele                           October 22, 2015   2.84  \n",
       "28  Shakira                         June 4, 2010       2.84  \n",
       "29  Crazy Frog                      June 16, 2009      2.82  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping ranks of most viewed videos on YouTube from Wikipedia\n",
    "\n",
    "rank=[]\n",
    "for i in driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[1]\"):\n",
    "    if len(rank)<30:\n",
    "        rank.append(i.text)\n",
    "    \n",
    "rank = pd.DataFrame(rank)\n",
    "rank.columns=['rank']\n",
    "\n",
    "#scraping names of most viewed videos on YouTube from Wikipedia\n",
    "\n",
    "name=[]\n",
    "for i in driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[2]\"):\n",
    "    if len(name)<30:\n",
    "        name.append(i.text)\n",
    "    \n",
    "name = pd.DataFrame(name)\n",
    "name.columns=['name']\n",
    "name['name'] = name['name'].astype(str).str[0:-4] # removing unnecessary data\n",
    "\n",
    "\n",
    "#scraping artists of most viewed videos on YouTube from Wikipedia\n",
    "\n",
    "artist=[]\n",
    "for i in driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[3]\"):\n",
    "    if len(artist)<30:\n",
    "        artist.append(i.text)\n",
    "    \n",
    "artist = pd.DataFrame(artist)\n",
    "artist.columns=['artist']\n",
    "\n",
    "#scraping upload date of most viewed videos on YouTube from Wikipedia\n",
    "\n",
    "date=[]\n",
    "for i in driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[5]\"):\n",
    "    if len(date)<30:\n",
    "        date.append(i.text)\n",
    "    \n",
    "date = pd.DataFrame(date)\n",
    "date.columns=['date']\n",
    "\n",
    "#scraping views of most viewed videos on YouTube from Wikipedia\n",
    "views=[]\n",
    "for i in driver.find_elements_by_xpath(\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[4]\"):\n",
    "    if len(views)<30:\n",
    "        views.append(i.text)\n",
    "    \n",
    "views = pd.DataFrame(views)\n",
    "views.columns=['views']\n",
    "\n",
    "youtube=pd.DataFrame({})\n",
    "youtube['Rank']=rank['rank']\n",
    "youtube['Name']=name['name']\n",
    "youtube['Artist']=artist['artist']\n",
    "youtube[\"Upload Date\"]=date['date']\n",
    "youtube['Views']=views['views']\n",
    "youtube\n",
    "# Details of most viewed videos on YouTube from Wikipedia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s international fixtures from bcci.tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.bcci.tv/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"/html/body/div[3]/div/div[2]/div[2]/nav/ul/li[1]/div[2]\").click() \n",
    "#selects drop down of International tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixtures=driver.find_element_by_xpath(\"/html/body/div[3]/div/div[2]/div[2]/nav/ul/li[1]/div[2]/div/ul/li[1]/a\").get_attribute('href')\n",
    "#obtaining fixtures URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(fixtures) #going to fixtures URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Final</td>\n",
       "      <td>ICC WORLD TEST CHAMPIONSHIP</td>\n",
       "      <td>The Ageas Bowl, Southampton</td>\n",
       "      <td>18 JUNE</td>\n",
       "      <td>15:00 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Trent Bridge, Nottingham</td>\n",
       "      <td>04 AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2nd Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Lord's, London</td>\n",
       "      <td>12 AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3rd Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Headingley, Leeds</td>\n",
       "      <td>25 AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4th Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>The Oval, London</td>\n",
       "      <td>02 SEPTEMBER</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5th Test</td>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>Old Trafford, Manchester</td>\n",
       "      <td>10 SEPTEMBER</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match Title                       Series                        Place  \\\n",
       "0  Final       ICC WORLD TEST CHAMPIONSHIP  The Ageas Bowl, Southampton   \n",
       "1  1st Test    ENGLAND V INDIA 2021         Trent Bridge, Nottingham      \n",
       "2  2nd Test    ENGLAND V INDIA 2021         Lord's, London                \n",
       "3  3rd Test    ENGLAND V INDIA 2021         Headingley, Leeds             \n",
       "4  4th Test    ENGLAND V INDIA 2021         The Oval, London              \n",
       "5  5th Test    ENGLAND V INDIA 2021         Old Trafford, Manchester      \n",
       "\n",
       "           Date       Time  \n",
       "0  18 JUNE       15:00 IST  \n",
       "1  04 AUGUST     15:30 IST  \n",
       "2  12 AUGUST     15:30 IST  \n",
       "3  25 AUGUST     15:30 IST  \n",
       "4  02 SEPTEMBER  15:30 IST  \n",
       "5  10 SEPTEMBER  15:30 IST  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping Match title of team India’s international fixtures from bcci.tv\n",
    "title=[]\n",
    "for i in driver.find_elements_by_xpath(\"//strong[@class='fixture__name fixture__name--with-margin']\"):\n",
    "    title.append(i.text)\n",
    "    \n",
    "title = pd.DataFrame(title)\n",
    "title.columns=['title']\n",
    "\n",
    "#scraping Series of team India’s international fixtures from bcci.tv\n",
    "series=[]\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='u-unskewed-text fixture__tournament-label u-truncated']\"):\n",
    "    series.append(i.text)\n",
    "    \n",
    "series = pd.DataFrame(series)\n",
    "series.columns=['series']\n",
    "\n",
    "#scraping place of team India’s international fixtures from bcci.tv\n",
    "place=[]\n",
    "for i in driver.find_elements_by_xpath(\"//p[@class='fixture__additional-info']/span\"):\n",
    "    place.append(i.text)\n",
    "    \n",
    "place = pd.DataFrame(place)\n",
    "place.columns=['place']\n",
    "\n",
    "#scraping Date of team India’s international fixtures from bcci.tv\n",
    "Dt=[]\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='fixture__full-date']\"):\n",
    "    Dt.append(i.text)\n",
    "    \n",
    "Dt = pd.DataFrame(Dt)\n",
    "Dt.columns=['Dt']\n",
    "Dt['Dt']=Dt['Dt'].str.replace('\\n',' ')\n",
    "Dt['Dt'] = Dt['Dt'].astype(str).str[0:-10] # removing time data\n",
    "\n",
    "#scraping Time of team India’s international fixtures from bcci.tv\n",
    "time=[]\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='fixture__time']\"):\n",
    "    time.append(i.text)\n",
    "    \n",
    "time = pd.DataFrame(time)\n",
    "time.columns=['time']\n",
    "\n",
    "bcci=pd.DataFrame({})\n",
    "bcci['Match Title']=title['title']\n",
    "bcci['Series']=series['series']\n",
    "bcci['Place']=place['place']\n",
    "bcci[\"Date\"]=Dt['Dt']\n",
    "bcci['Time']=time['time']\n",
    "bcci\n",
    "# Details team India’s international fixtures from bcci.tv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Scrape the details of selenium exception from guru99.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.guru99.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "selenium=driver.find_element_by_xpath(\"(//a[@target='_top'])[3]\").get_attribute('href')\n",
    "#obtaining selenium URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(selenium)   #going to selenium URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "exception=driver.find_element_by_xpath(\"(//td[@class='responsivetable'])[69]/a\").get_attribute('href')\n",
    "#obtaining \"Selenium Exception Handling (Common Exceptions List)\" URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(exception)  #going to \"Selenium Exception Handling (Common Exceptions List)\" URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exception Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElementNotVisibleException</td>\n",
       "      <td>This type of Selenium exception occurs when an existing element in DOM has a feature set as hidden.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an element is presented in the DOM, but you can be able to select. Therefore, it is not possible to interact.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not be found.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to be switched to does not exist.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NoAlertPresentException</td>\n",
       "      <td>This Exception occurs when you switch to no presented alert.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NoSuchWindowException</td>\n",
       "      <td>This Exception occurs if the window target to be switch does not exist.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>StaleElementReferenceException</td>\n",
       "      <td>This Selenium exception occurs happens when the web element is detached from the current DOM.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SessionNotFoundException</td>\n",
       "      <td>The WebDriver is acting after you quit the browser.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TimeoutException</td>\n",
       "      <td>Thrown when there is not enough time for a command to be completed. For Example, the element searched wasn't found in the specified time.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WebDriverException</td>\n",
       "      <td>This Exception takes place when the WebDriver is acting right after you close the browser.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ConnectionClosedException</td>\n",
       "      <td>This type of Exception takes place when there is a disconnection in the driver.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ElementClickInterceptedException</td>\n",
       "      <td>The command may not be completed as the element receiving the events is concealing the element which was requested clicked.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ElementNotInteractableException</td>\n",
       "      <td>This Selenium exception is thrown when any element is presented in the DOM. However, it is impossible to interact with such an element.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ErrorInResponseException</td>\n",
       "      <td>This happens while interacting with the Firefox extension or the remote driver server.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ErrorHandler.UnknownServerException</td>\n",
       "      <td>Exception is used as a placeholder in case if the server returns an error without a stack trace.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ImeActivationFailedException</td>\n",
       "      <td>This expectation will occur when IME engine activation has failed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ImeNotAvailableException</td>\n",
       "      <td>It takes place when IME support is unavailable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>InsecureCertificateException</td>\n",
       "      <td>Navigation made the user agent to hit a certificate warning. This can cause by an invalid or expired TLS certificate.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>InvalidArgumentException</td>\n",
       "      <td>It occurs when an argument does not belong to the expected type.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>InvalidCookieDomainException</td>\n",
       "      <td>This happens when you try to add a cookie under a different domain instead of current URL.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>InvalidCoordinatesException</td>\n",
       "      <td>This type of Exception matches an interacting operation that is not valid.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>InvalidElementStateExceptio</td>\n",
       "      <td>It occurs when command can't be finished when the element is invalid.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>InvalidSessionIdException</td>\n",
       "      <td>This Exception took place when the given session ID is not included in the list of active sessions. It means the session does not exist or is inactive either.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>InvalidSwitchToTargetException</td>\n",
       "      <td>This occurs when the frame or window target to be switched does not exist.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>JavascriptException</td>\n",
       "      <td>This issue occurs while executing JavaScript given by the user.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>JsonException</td>\n",
       "      <td>It occurs when you afford to get the session when the session is not created.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NoSuchAttributeException</td>\n",
       "      <td>This kind of Exception occurs when the attribute of an element could not be found.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MoveTargetOutOfBoundsException</td>\n",
       "      <td>It takes place if the target provided to the ActionChains move() methodology is not valid. For Example, out of the document.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NoSuchContextException</td>\n",
       "      <td>ContextAware does mobile device testing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NoSuchCookieException</td>\n",
       "      <td>This Exception occurs when no cookie matching with the given pathname found for all the associated cookies of the currently browsing document.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NotFoundException</td>\n",
       "      <td>This Exception is a subclass of WebDriverException. This will occur when an element on the DOM does not exist.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>RemoteDriverServerException</td>\n",
       "      <td>This Selenium exception is thrown when the server is not responding because of the problem that the capabilities described are not proper.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ScreenshotException</td>\n",
       "      <td>It is not possible to capture a screen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SessionNotCreatedException</td>\n",
       "      <td>It happens when a new session could not be successfully created.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>UnableToSetCookieException</td>\n",
       "      <td>This occurs if a driver is unable to set a cookie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>UnexpectedTagNameException</td>\n",
       "      <td>Happens if a support class did not get a web element as expected.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>UnhandledAlertException</td>\n",
       "      <td>This expectation occurs when there is an alert, but WebDriver is not able to perform Alert operation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>UnexpectedAlertPresentException</td>\n",
       "      <td>It occurs when there is the appearance of an unexpected alert.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>UnknownMethodException</td>\n",
       "      <td>This Exception happens when the requested command matches with a known URL but and not matching with a methodology for a specific URL.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>UnreachableBrowserException</td>\n",
       "      <td>This Exception occurs only when the browser is not able to be opened or crashed because of some reason.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>UnsupportedCommandException</td>\n",
       "      <td>This occurs when remote WebDriver does n't send valid commands as expected.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Exception Name  \\\n",
       "1   ElementNotVisibleException            \n",
       "2   ElementNotSelectableException         \n",
       "3   NoSuchElementException                \n",
       "4   NoSuchFrameException                  \n",
       "5   NoAlertPresentException               \n",
       "6   NoSuchWindowException                 \n",
       "7   StaleElementReferenceException        \n",
       "8   SessionNotFoundException              \n",
       "9   TimeoutException                      \n",
       "10  WebDriverException                    \n",
       "11  ConnectionClosedException             \n",
       "12  ElementClickInterceptedException      \n",
       "13  ElementNotInteractableException       \n",
       "14  ErrorInResponseException              \n",
       "15  ErrorHandler.UnknownServerException   \n",
       "16  ImeActivationFailedException          \n",
       "17  ImeNotAvailableException              \n",
       "18  InsecureCertificateException          \n",
       "19  InvalidArgumentException              \n",
       "20  InvalidCookieDomainException          \n",
       "21  InvalidCoordinatesException           \n",
       "22  InvalidElementStateExceptio           \n",
       "23  InvalidSessionIdException             \n",
       "24  InvalidSwitchToTargetException        \n",
       "25  JavascriptException                   \n",
       "26  JsonException                         \n",
       "27  NoSuchAttributeException              \n",
       "28  MoveTargetOutOfBoundsException        \n",
       "29  NoSuchContextException                \n",
       "30  NoSuchCookieException                 \n",
       "31  NotFoundException                     \n",
       "32  RemoteDriverServerException           \n",
       "33  ScreenshotException                   \n",
       "34  SessionNotCreatedException            \n",
       "35  UnableToSetCookieException            \n",
       "36  UnexpectedTagNameException            \n",
       "37  UnhandledAlertException               \n",
       "38  UnexpectedAlertPresentException       \n",
       "39  UnknownMethodException                \n",
       "40  UnreachableBrowserException           \n",
       "41  UnsupportedCommandException           \n",
       "\n",
       "                                                                                                                                                       Description  \n",
       "1   This type of Selenium exception occurs when an existing element in DOM has a feature set as hidden.                                                             \n",
       "2   This Selenium exception occurs when an element is presented in the DOM, but you can be able to select. Therefore, it is not possible to interact.               \n",
       "3   This Exception occurs if an element could not be found.                                                                                                         \n",
       "4   This Exception occurs if the frame target to be switched to does not exist.                                                                                     \n",
       "5   This Exception occurs when you switch to no presented alert.                                                                                                    \n",
       "6   This Exception occurs if the window target to be switch does not exist.                                                                                         \n",
       "7   This Selenium exception occurs happens when the web element is detached from the current DOM.                                                                   \n",
       "8   The WebDriver is acting after you quit the browser.                                                                                                             \n",
       "9   Thrown when there is not enough time for a command to be completed. For Example, the element searched wasn't found in the specified time.                       \n",
       "10  This Exception takes place when the WebDriver is acting right after you close the browser.                                                                      \n",
       "11  This type of Exception takes place when there is a disconnection in the driver.                                                                                 \n",
       "12  The command may not be completed as the element receiving the events is concealing the element which was requested clicked.                                     \n",
       "13  This Selenium exception is thrown when any element is presented in the DOM. However, it is impossible to interact with such an element.                         \n",
       "14  This happens while interacting with the Firefox extension or the remote driver server.                                                                          \n",
       "15  Exception is used as a placeholder in case if the server returns an error without a stack trace.                                                                \n",
       "16  This expectation will occur when IME engine activation has failed.                                                                                              \n",
       "17  It takes place when IME support is unavailable.                                                                                                                 \n",
       "18  Navigation made the user agent to hit a certificate warning. This can cause by an invalid or expired TLS certificate.                                           \n",
       "19  It occurs when an argument does not belong to the expected type.                                                                                                \n",
       "20  This happens when you try to add a cookie under a different domain instead of current URL.                                                                      \n",
       "21  This type of Exception matches an interacting operation that is not valid.                                                                                      \n",
       "22  It occurs when command can't be finished when the element is invalid.                                                                                           \n",
       "23  This Exception took place when the given session ID is not included in the list of active sessions. It means the session does not exist or is inactive either.  \n",
       "24  This occurs when the frame or window target to be switched does not exist.                                                                                      \n",
       "25  This issue occurs while executing JavaScript given by the user.                                                                                                 \n",
       "26  It occurs when you afford to get the session when the session is not created.                                                                                   \n",
       "27  This kind of Exception occurs when the attribute of an element could not be found.                                                                              \n",
       "28  It takes place if the target provided to the ActionChains move() methodology is not valid. For Example, out of the document.                                    \n",
       "29  ContextAware does mobile device testing.                                                                                                                        \n",
       "30  This Exception occurs when no cookie matching with the given pathname found for all the associated cookies of the currently browsing document.                  \n",
       "31  This Exception is a subclass of WebDriverException. This will occur when an element on the DOM does not exist.                                                  \n",
       "32  This Selenium exception is thrown when the server is not responding because of the problem that the capabilities described are not proper.                      \n",
       "33  It is not possible to capture a screen.                                                                                                                         \n",
       "34  It happens when a new session could not be successfully created.                                                                                                \n",
       "35  This occurs if a driver is unable to set a cookie.                                                                                                              \n",
       "36  Happens if a support class did not get a web element as expected.                                                                                               \n",
       "37  This expectation occurs when there is an alert, but WebDriver is not able to perform Alert operation.                                                           \n",
       "38  It occurs when there is the appearance of an unexpected alert.                                                                                                  \n",
       "39  This Exception happens when the requested command matches with a known URL but and not matching with a methodology for a specific URL.                          \n",
       "40  This Exception occurs only when the browser is not able to be opened or crashed because of some reason.                                                         \n",
       "41  This occurs when remote WebDriver does n't send valid commands as expected.                                                                                     "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Exception Name\n",
    "\n",
    "excep_name=[]\n",
    "for i in driver.find_elements_by_xpath(\"//table[@class='table table-striped']/tbody/tr/td[1]\"):\n",
    "    excep_name.append(i.text)\n",
    "    \n",
    "excep_name = pd.DataFrame(excep_name)\n",
    "excep_name.columns=['excep_name']\n",
    "\n",
    "#scraping Description\n",
    "\n",
    "desc=[]\n",
    "for i in driver.find_elements_by_xpath(\"//table[@class='table table-striped']/tbody/tr/td[2]\"):\n",
    "    desc.append(i.text)\n",
    "    \n",
    "desc = pd.DataFrame(desc)\n",
    "desc.columns=['desc']\n",
    "\n",
    "selenium=pd.DataFrame({})\n",
    "selenium['Exception Name']=excep_name['excep_name']\n",
    "selenium['Description']=desc['desc']\n",
    "selenium.drop(index=selenium.index[0], axis=0,inplace=True) #dropping the first row as it is unnecessary row\n",
    "selenium\n",
    "# Details of selenium exception from guru99.com.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Scrape the details of State-wise GDP of India from statisticstime.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='http://statisticstimes.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"(//button[@class='dropbtn'])[2]\").click()\n",
    "#selects drop down of Economy tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eco=driver.find_element_by_xpath(\"(//div[@class='dropdown-content'])/a[3]\").get_attribute('href')\n",
    "#Extracting \"India\" URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(eco) #going to \"India\" URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp=driver.find_element_by_xpath(\"(//ul[@style='list-style-type:none;margin-left:20px;'])/li/a\").get_attribute('href')\n",
    "#selects drop down of Economy tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(gdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(19-20)</th>\n",
       "      <th>GSDP(18-19</th>\n",
       "      <th>Share(2019)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   State Rank                      State GSDP(19-20) GSDP(18-19 Share(2019)  \\\n",
       "0   1          Maharashtra                -           2,632,792  13.94%       \n",
       "1   2          Tamil Nadu                 1,845,853   1,630,208  8.63%        \n",
       "2   3          Uttar Pradesh              1,687,818   1,584,764  8.39%        \n",
       "3   4          Gujarat                    -           1,502,899  7.96%        \n",
       "4   5          Karnataka                  1,631,977   1,493,127  7.91%        \n",
       "5   6          West Bengal                1,253,832   1,089,898  5.77%        \n",
       "6   7          Rajasthan                  1,020,989   942,586    4.99%        \n",
       "7   8          Andhra Pradesh             972,782     862,957    4.57%        \n",
       "8   9          Telangana                  969,604     861,031    4.56%        \n",
       "9   10         Madhya Pradesh             906,672     809,592    4.29%        \n",
       "10  11         Kerala                     -           781,653    4.14%        \n",
       "11  12         Delhi                      856,112     774,870    4.10%        \n",
       "12  13         Haryana                    831,610     734,163    3.89%        \n",
       "13  14         Bihar                      611,804     530,363    2.81%        \n",
       "14  15         Punjab                     574,760     526,376    2.79%        \n",
       "15  16         Odisha                     521,275     487,805    2.58%        \n",
       "16  17         Assam                      -           315,881    1.67%        \n",
       "17  18         Chhattisgarh               329,180     304,063    1.61%        \n",
       "18  19         Jharkhand                  328,598     297,204    1.57%        \n",
       "19  20         Uttarakhand                -           245,895    1.30%        \n",
       "20  21         Jammu & Kashmir            -           155,956    0.83%        \n",
       "21  22         Himachal Pradesh           165,472     153,845    0.81%        \n",
       "22  23         Goa                        80,449      73,170     0.39%        \n",
       "23  24         Tripura                    55,984      49,845     0.26%        \n",
       "24  25         Chandigarh                 -           42,114     0.22%        \n",
       "25  26         Puducherry                 38,253      34,433     0.18%        \n",
       "26  27         Meghalaya                  36,572      33,481     0.18%        \n",
       "27  28         Sikkim                     32,496      28,723     0.15%        \n",
       "28  29         Manipur                    31,790      27,870     0.15%        \n",
       "29  30         Nagaland                   -           27,283     0.14%        \n",
       "30  31         Arunachal Pradesh          -           24,603     0.13%        \n",
       "31  32         Mizoram                    26,503      22,287     0.12%        \n",
       "32  33         Andaman & Nicobar Islands  -           -          -            \n",
       "\n",
       "   GDP($ billion)  \n",
       "0   399.921        \n",
       "1   247.629        \n",
       "2   240.726        \n",
       "3   228.290        \n",
       "4   226.806        \n",
       "5   165.556        \n",
       "6   143.179        \n",
       "7   131.083        \n",
       "8   130.791        \n",
       "9   122.977        \n",
       "10  118.733        \n",
       "11  117.703        \n",
       "12  111.519        \n",
       "13  80.562         \n",
       "14  79.957         \n",
       "15  74.098         \n",
       "16  47.982         \n",
       "17  46.187         \n",
       "18  45.145         \n",
       "19  37.351         \n",
       "20  23.690         \n",
       "21  23.369         \n",
       "22  11.115         \n",
       "23  7.571          \n",
       "24  6.397          \n",
       "25  5.230          \n",
       "26  5.086          \n",
       "27  4.363          \n",
       "28  4.233          \n",
       "29  4.144          \n",
       "30  3.737          \n",
       "31  3.385          \n",
       "32  -              "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Ranks of states\n",
    "\n",
    "st_rank=[]\n",
    "for i in driver.find_elements_by_xpath(\"//tr[@role='row']/td[1]\"):\n",
    "    if len(st_rank)<33:\n",
    "        st_rank.append(i.text)\n",
    "    \n",
    "st_rank = pd.DataFrame(st_rank)\n",
    "st_rank.columns=['st_rank']\n",
    "\n",
    "# Scraping states\n",
    "\n",
    "states=[]\n",
    "for i in driver.find_elements_by_xpath(\"//tr[@role='row']/td[2]\"):\n",
    "    if len(states)<33:\n",
    "        states.append(i.text)\n",
    "    \n",
    "states = pd.DataFrame(states)\n",
    "states.columns=['states']\n",
    "\n",
    "\n",
    "# Scraping GSDP(19-20)\n",
    "\n",
    "gdsp1920=[]\n",
    "for i in driver.find_elements_by_xpath(\"//tr[@role='row']/td[3]\"):\n",
    "    if len(gdsp1920)<33:\n",
    "        gdsp1920.append(i.text)\n",
    "    \n",
    "gdsp1920 = pd.DataFrame(gdsp1920)\n",
    "gdsp1920.columns=['gdsp1920']\n",
    "\n",
    "# Scraping GSDP(18-19)\n",
    "\n",
    "gdsp1819=[]\n",
    "for i in driver.find_elements_by_xpath(\"//tr[@role='row']/td[4]\"):\n",
    "    if len(gdsp1819)<33:\n",
    "        gdsp1819.append(i.text)\n",
    "    \n",
    "gdsp1819 = pd.DataFrame(gdsp1819)\n",
    "gdsp1819.columns=['gdsp1819']\n",
    "\n",
    "# Scraping Share(2019)\n",
    "\n",
    "share=[]\n",
    "for i in driver.find_elements_by_xpath(\"//tr[@role='row']/td[5]\"):\n",
    "    if len(share)<33:\n",
    "        share.append(i.text)\n",
    "    \n",
    "share = pd.DataFrame(share)\n",
    "share.columns=['share']\n",
    "\n",
    "# Scraping GDP($ billion)\n",
    "\n",
    "gdp=[]\n",
    "for i in driver.find_elements_by_xpath(\"//tr[@role='row']/td[6]\"):\n",
    "    if len(gdp)<33:\n",
    "        gdp.append(i.text)\n",
    "    \n",
    "gdp = pd.DataFrame(gdp)\n",
    "gdp.columns=['gdp']\n",
    "\n",
    "\n",
    "st_wise_gdp=pd.DataFrame({})\n",
    "st_wise_gdp['State Rank']=st_rank['st_rank']\n",
    "st_wise_gdp['State']=states['states']\n",
    "st_wise_gdp['GSDP(19-20)']=gdsp1920['gdsp1920']\n",
    "st_wise_gdp[\"GSDP(18-19\"]=gdsp1819['gdsp1819']\n",
    "st_wise_gdp['Share(2019)']=share['share']\n",
    "st_wise_gdp['GDP($ billion)']=gdp['gdp']\n",
    "st_wise_gdp\n",
    "# Details of State-wise GDP of India from statisticstime.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Scrape the details of trending repositories on Github.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://github.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "github=driver.find_element_by_xpath(\"/html/body/div[1]/header/div[3]/nav/a[4]\").get_attribute('href')\n",
    "# Extracting \"Explore\" URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(github) #going to \"Explore\" URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "repositories=driver.find_element_by_xpath(\"/html/body/div[4]/main/div[2]/div/div/div[3]/div[1]/div[1]/h2/a\").get_attribute('href')\n",
    "# Extracting \"Trending repositories today\" URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(repositories) # going to \"Trending repositories today\" URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Repository Title of trending repositories on Github.com.\n",
    "repo_title=[]\n",
    "for i in driver.find_elements_by_xpath(\"//h1[@class='h3 lh-condensed']\"):\n",
    "    repo_title.append(i.text)\n",
    "    \n",
    "repo_title = pd.DataFrame(repo_title)\n",
    "repo_title.columns=['repo_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "giturl=[] #scraping all urls of all repositries\n",
    "for j in driver.find_elements_by_xpath(\"//h1[@class='h3 lh-condensed']/a\"):\n",
    "            giturl.append(j.get_attribute('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Title</th>\n",
       "      <th>Repository Description</th>\n",
       "      <th>Contributors Count</th>\n",
       "      <th>Language Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PaperMC / Paper</td>\n",
       "      <td>High performance Spigot fork that aims to fix gameplay and mechanics inconsistencies</td>\n",
       "      <td>245</td>\n",
       "      <td>Shell 77.9% Java 22.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hasura / graphql-engine</td>\n",
       "      <td>Blazing fast, instant realtime GraphQL APIs on your DB with fine grained access control, also trigger webhooks on database events.</td>\n",
       "      <td>357</td>\n",
       "      <td>Haskell 35.3% JavaScript 20.7% TypeScript 19.4% Go 10.5% Python 7.3% CSS 1.8% Other 5.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neovim / neovim</td>\n",
       "      <td>Vim-fork focused on extensibility and usability</td>\n",
       "      <td>667</td>\n",
       "      <td>Vim script 44.3% C 34.8% Lua 19.0% Python 0.8% CMake 0.4% Shell 0.3% Other 0.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>udacity / nd064_course_1</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>Python 56.4% HTML 24.1% CSS 12.4% Go 4.4% Dockerfile 2.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alpinejs / alpine</td>\n",
       "      <td>A rugged, minimal framework for composing JavaScript behavior in your markup.</td>\n",
       "      <td>127</td>\n",
       "      <td>HTML 93.5% JavaScript 6.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>madMAx43v3r / chia-plotter</td>\n",
       "      <td>-</td>\n",
       "      <td>18</td>\n",
       "      <td>C 68.5% C++ 31.0% Other 0.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>iptv-org / iptv</td>\n",
       "      <td>Collection of publicly available IPTV channels from all over the world</td>\n",
       "      <td>84</td>\n",
       "      <td>JavaScript 100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>zzanehip / The-OldOS-Project</td>\n",
       "      <td>Recreating a fully functional version of iOS 4 in SwiftUI.</td>\n",
       "      <td>5</td>\n",
       "      <td>Swift 93.4% Objective-C 5.9% Other 0.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ytdl-org / youtube-dl</td>\n",
       "      <td>Command-line program to download videos from YouTube.com and other video sites</td>\n",
       "      <td>768</td>\n",
       "      <td>Python 99.6% Other 0.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>biancangming / wtv</td>\n",
       "      <td>解决电脑、手机看电视直播的苦恼，收集各种直播源，电视直播网站</td>\n",
       "      <td>-</td>\n",
       "      <td>Python 100.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>maziarraissi / Applied-Deep-Learning</td>\n",
       "      <td>Applied Deep Learning</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>jwasham / coding-interview-university</td>\n",
       "      <td>A complete computer science study plan to become a software engineer.</td>\n",
       "      <td>197</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>chrxh / alien</td>\n",
       "      <td>alien is a GPU-accelerated artificial life simulation program.</td>\n",
       "      <td>-</td>\n",
       "      <td>C++ 76.4% Cuda 21.9% Other 1.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>the-hyp0cr1t3 / DSA-Training-2021</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>yangtingxiao / QuantumultX</td>\n",
       "      <td>脚本，自用</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MuriungiPatrick / Bootstrap-5-portfolio-template</td>\n",
       "      <td>Learning Bootstrap 5 with SASS</td>\n",
       "      <td>-</td>\n",
       "      <td>JavaScript 56.6% CSS 32.3% HTML 9.1% SCSS 2.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ashishpatel26 / 500-AI-Machine-learning-Deep-learning-Computer-vision-NLP-Projects-with-code</td>\n",
       "      <td>500 AI Machine learning Deep learning Computer vision NLP Projects with code</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>jina-ai / jina</td>\n",
       "      <td>An easier way to build neural search on the cloud</td>\n",
       "      <td>97</td>\n",
       "      <td>Python 94.2% HTML 2.4% CSS 1.1% Shell 0.9% Dockerfile 0.6% JavaScript 0.5% EJS 0.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EbookFoundation / free-programming-books</td>\n",
       "      <td>📚 Freely available programming books</td>\n",
       "      <td>1,617</td>\n",
       "      <td>github-pages Active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>hlissner / doom-emacs</td>\n",
       "      <td>An Emacs framework for the stubborn martian hacker</td>\n",
       "      <td>463</td>\n",
       "      <td>Emacs Lisp 95.3% YASnippet 4.4% Nix 0.2% Shell 0.1% HTML 0.0% JavaScript 0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>drawrowfly / tiktok-scraper</td>\n",
       "      <td>TikTok Scraper. Download video posts, collect user/trend/hashtag/music feed metadata, sign URL and etc.</td>\n",
       "      <td>21</td>\n",
       "      <td>TypeScript 96.3% JavaScript 3.5% Dockerfile 0.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Genymobile / scrcpy</td>\n",
       "      <td>Display and control your Android device</td>\n",
       "      <td>68</td>\n",
       "      <td>C 63.5% Java 30.5% Roff 1.7% Meson 1.6% Makefile 1.4% Shell 1.0% Other 0.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>atom / atom</td>\n",
       "      <td>The hackable text editor</td>\n",
       "      <td>479</td>\n",
       "      <td>JavaScript 88.2% Less 8.7% CoffeeScript 3.0% Shell 0.1% Batchfile 0.0% Dockerfile 0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>nushell / nushell</td>\n",
       "      <td>A new type of shell</td>\n",
       "      <td>229</td>\n",
       "      <td>Rust 100.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                Repository Title  \\\n",
       "0   PaperMC / Paper                                                                                \n",
       "1   hasura / graphql-engine                                                                        \n",
       "2   neovim / neovim                                                                                \n",
       "3   udacity / nd064_course_1                                                                       \n",
       "4   alpinejs / alpine                                                                              \n",
       "5   madMAx43v3r / chia-plotter                                                                     \n",
       "6   iptv-org / iptv                                                                                \n",
       "7   zzanehip / The-OldOS-Project                                                                   \n",
       "8   ytdl-org / youtube-dl                                                                          \n",
       "9   biancangming / wtv                                                                             \n",
       "10  maziarraissi / Applied-Deep-Learning                                                           \n",
       "11  jwasham / coding-interview-university                                                          \n",
       "12  chrxh / alien                                                                                  \n",
       "13  the-hyp0cr1t3 / DSA-Training-2021                                                              \n",
       "14  yangtingxiao / QuantumultX                                                                     \n",
       "15  MuriungiPatrick / Bootstrap-5-portfolio-template                                               \n",
       "16  ashishpatel26 / 500-AI-Machine-learning-Deep-learning-Computer-vision-NLP-Projects-with-code   \n",
       "17  jina-ai / jina                                                                                 \n",
       "18  EbookFoundation / free-programming-books                                                       \n",
       "19  hlissner / doom-emacs                                                                          \n",
       "20  drawrowfly / tiktok-scraper                                                                    \n",
       "21  Genymobile / scrcpy                                                                            \n",
       "22  atom / atom                                                                                    \n",
       "23  nushell / nushell                                                                              \n",
       "\n",
       "                                                                                                                Repository Description  \\\n",
       "0   High performance Spigot fork that aims to fix gameplay and mechanics inconsistencies                                                 \n",
       "1   Blazing fast, instant realtime GraphQL APIs on your DB with fine grained access control, also trigger webhooks on database events.   \n",
       "2   Vim-fork focused on extensibility and usability                                                                                      \n",
       "3   -                                                                                                                                    \n",
       "4   A rugged, minimal framework for composing JavaScript behavior in your markup.                                                        \n",
       "5   -                                                                                                                                    \n",
       "6   Collection of publicly available IPTV channels from all over the world                                                               \n",
       "7   Recreating a fully functional version of iOS 4 in SwiftUI.                                                                           \n",
       "8   Command-line program to download videos from YouTube.com and other video sites                                                       \n",
       "9   解决电脑、手机看电视直播的苦恼，收集各种直播源，电视直播网站                                                                                                       \n",
       "10  Applied Deep Learning                                                                                                                \n",
       "11  A complete computer science study plan to become a software engineer.                                                                \n",
       "12  alien is a GPU-accelerated artificial life simulation program.                                                                       \n",
       "13  -                                                                                                                                    \n",
       "14  脚本，自用                                                                                                                                \n",
       "15  Learning Bootstrap 5 with SASS                                                                                                       \n",
       "16  500 AI Machine learning Deep learning Computer vision NLP Projects with code                                                         \n",
       "17  An easier way to build neural search on the cloud                                                                                    \n",
       "18  📚 Freely available programming books                                                                                                 \n",
       "19  An Emacs framework for the stubborn martian hacker                                                                                   \n",
       "20  TikTok Scraper. Download video posts, collect user/trend/hashtag/music feed metadata, sign URL and etc.                              \n",
       "21  Display and control your Android device                                                                                              \n",
       "22  The hackable text editor                                                                                                             \n",
       "23  A new type of shell                                                                                                                  \n",
       "\n",
       "   Contributors Count  \\\n",
       "0   245                 \n",
       "1   357                 \n",
       "2   667                 \n",
       "3   2                   \n",
       "4   127                 \n",
       "5   18                  \n",
       "6   84                  \n",
       "7   5                   \n",
       "8   768                 \n",
       "9   -                   \n",
       "10  -                   \n",
       "11  197                 \n",
       "12  -                   \n",
       "13  5                   \n",
       "14  -                   \n",
       "15  -                   \n",
       "16  -                   \n",
       "17  97                  \n",
       "18  1,617               \n",
       "19  463                 \n",
       "20  21                  \n",
       "21  68                  \n",
       "22  479                 \n",
       "23  229                 \n",
       "\n",
       "                                                                               Language Used  \n",
       "0   Shell 77.9% Java 22.1%                                                                    \n",
       "1   Haskell 35.3% JavaScript 20.7% TypeScript 19.4% Go 10.5% Python 7.3% CSS 1.8% Other 5.0%  \n",
       "2   Vim script 44.3% C 34.8% Lua 19.0% Python 0.8% CMake 0.4% Shell 0.3% Other 0.4%           \n",
       "3   Python 56.4% HTML 24.1% CSS 12.4% Go 4.4% Dockerfile 2.7%                                 \n",
       "4   HTML 93.5% JavaScript 6.5%                                                                \n",
       "5   C 68.5% C++ 31.0% Other 0.5%                                                              \n",
       "6   JavaScript 100.0%                                                                         \n",
       "7   Swift 93.4% Objective-C 5.9% Other 0.7%                                                   \n",
       "8   Python 99.6% Other 0.4%                                                                   \n",
       "9   Python 100.0%                                                                             \n",
       "10  -                                                                                         \n",
       "11                                                                                            \n",
       "12  C++ 76.4% Cuda 21.9% Other 1.7%                                                           \n",
       "13                                                                                            \n",
       "14  -                                                                                         \n",
       "15  JavaScript 56.6% CSS 32.3% HTML 9.1% SCSS 2.0%                                            \n",
       "16  -                                                                                         \n",
       "17  Python 94.2% HTML 2.4% CSS 1.1% Shell 0.9% Dockerfile 0.6% JavaScript 0.5% EJS 0.3%       \n",
       "18  github-pages Active                                                                       \n",
       "19  Emacs Lisp 95.3% YASnippet 4.4% Nix 0.2% Shell 0.1% HTML 0.0% JavaScript 0.0%             \n",
       "20  TypeScript 96.3% JavaScript 3.5% Dockerfile 0.2%                                          \n",
       "21  C 63.5% Java 30.5% Roff 1.7% Meson 1.6% Makefile 1.4% Shell 1.0% Other 0.3%               \n",
       "22  JavaScript 88.2% Less 8.7% CoffeeScript 3.0% Shell 0.1% Batchfile 0.0% Dockerfile 0.0%    \n",
       "23  Rust 100.0%                                                                               "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_desc=[]\n",
    "lang=[]\n",
    "contributors=[]\n",
    "\n",
    "for i in giturl:\n",
    "    url=i\n",
    "    driver.get(url)\n",
    "    sleep(4)\n",
    "\n",
    "\n",
    "        \n",
    "# Scraping Repository description of trending repositories on Github.com.\n",
    "\n",
    "    try:\n",
    "        rd=driver.find_element_by_xpath(\"//p[@class='f4 mt-3']\")\n",
    "        repo_desc.append(rd.text)\n",
    "    except NoSuchElementException:\n",
    "        repo_desc.append('-')\n",
    "        \n",
    "# Scraping language used of trending repositories on Github.com.\n",
    "\n",
    "    try:\n",
    "        lg=driver.find_element_by_xpath(\"(//div[@class='BorderGrid-cell']/ul)[last()]\")\n",
    "        lang.append(lg.text)\n",
    "    except NoSuchElementException:\n",
    "        lang.append('-')\n",
    "        \n",
    "# Scraping contributors of trending repositories on Github.com.\n",
    "        \n",
    "    try:#scraping contributors count\n",
    "\n",
    "        con=driver.find_element_by_xpath(\"//h2[@class='h4 mb-3']/a[contains(text(),'Contributors')]/span\")\n",
    "\n",
    "        contributors.append(con.text)\n",
    "\n",
    "    except:#handling no such element exception\n",
    "\n",
    "        contributors.append('-') \n",
    "        \n",
    "        \n",
    "\n",
    "repo_desc = pd.DataFrame(repo_desc)\n",
    "repo_desc.columns=['repo_desc']   \n",
    "        \n",
    "lang = pd.DataFrame(lang)\n",
    "lang.columns=['lang']\n",
    "lang['lang']=lang['lang'].str.replace('\\n',' ')\n",
    "        \n",
    "contributors = pd.DataFrame(contributors)\n",
    "contributors.columns=['contributors']        \n",
    "\n",
    "\n",
    "github_repository=pd.DataFrame({})\n",
    "github_repository['Repository Title']=repo_title['repo_title']\n",
    "github_repository['Repository Description']=repo_desc['repo_desc']\n",
    "github_repository['Contributors Count']=contributors['contributors']\n",
    "github_repository[\"Language Used\"]=lang['lang']\n",
    "github_repository\n",
    "# Details of trending repositories on Github.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Scrape the details of top 100 songs on billiboard.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.billboard.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "charts=driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[2]/header/div/ul/li[1]/a\").get_attribute('href')\n",
    "# Extracting \"Chart\" URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(charts) #going to \"Chart\" URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"/html/body/main/div[2]/div/div[1]/a/div[2]/div[2]/div[1]\").click()\n",
    "# Clicks on hot 100-page link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks on Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Butter</td>\n",
       "      <td>BTS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good 4 U</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Levitating</td>\n",
       "      <td>Dua Lipa Featuring DaBaby</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leave The Door Open</td>\n",
       "      <td>Silk Sonic (Bruno Mars &amp; Anderson .Paak)</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Save Your Tears</td>\n",
       "      <td>The Weeknd &amp; Ariana Grande</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>All I Know So Far</td>\n",
       "      <td>P!nk</td>\n",
       "      <td>87</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Hold On</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>86</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Wasted On You</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>98</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Outside</td>\n",
       "      <td>MO3 X OG Bobby Billions</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Botella Tras Botella</td>\n",
       "      <td>Gera MX + Christian Nodal</td>\n",
       "      <td>-</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Song Name                               Artist Name  \\\n",
       "0   Butter                BTS                                        \n",
       "1   Good 4 U              Olivia Rodrigo                             \n",
       "2   Levitating            Dua Lipa Featuring DaBaby                  \n",
       "3   Leave The Door Open   Silk Sonic (Bruno Mars & Anderson .Paak)   \n",
       "4   Save Your Tears       The Weeknd & Ariana Grande                 \n",
       "..              ...                              ...                 \n",
       "95  All I Know So Far     P!nk                                       \n",
       "96  Hold On               Justin Bieber                              \n",
       "97  Wasted On You         Morgan Wallen                              \n",
       "98  Outside               MO3 X OG Bobby Billions                    \n",
       "99  Botella Tras Botella  Gera MX + Christian Nodal                  \n",
       "\n",
       "   Last Week Rank Peak Rank Weeks on Board  \n",
       "0   1              1         2              \n",
       "1   2              1         3              \n",
       "2   4              2         35             \n",
       "3   5              1         13             \n",
       "4   7              1         25             \n",
       ".. ..             ..         ..             \n",
       "95  87             74        3              \n",
       "96  86             20        13             \n",
       "97  98             9         19             \n",
       "98  -              99        1              \n",
       "99  -              60        4              \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping song name of top 100 songs on billiboard.com\n",
    "\n",
    "song=[]\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='chart-element__information__song text--truncate color--primary']\"):\n",
    "    song.append(i.text)\n",
    "    \n",
    "song = pd.DataFrame(song)\n",
    "song.columns=['song']\n",
    "\n",
    "# Scraping artist name of top 100 songs on billiboard.com\n",
    "\n",
    "artist=[]\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='chart-element__information__artist text--truncate color--secondary']\"):\n",
    "    artist.append(i.text)\n",
    "    \n",
    "artist = pd.DataFrame(artist)\n",
    "artist.columns=['artist']\n",
    "\n",
    "\n",
    "# Scraping Last week rank of top 100 songs on billiboard.com\n",
    "\n",
    "last=[]\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--last']\"):\n",
    "    last.append(i.text)\n",
    "    \n",
    "last = pd.DataFrame(last)\n",
    "last.columns=['last']\n",
    "\n",
    "# Scraping Peak rank of top 100 songs on billiboard.com\n",
    "\n",
    "peak=[]\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--peak']\"):\n",
    "    peak.append(i.text)\n",
    "    \n",
    "peak = pd.DataFrame(peak)\n",
    "peak.columns=['peak']\n",
    "\n",
    "# Scraping Weeks on board of top 100 songs on billiboard.com\n",
    "\n",
    "week=[]\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='chart-element__meta text--center color--secondary text--week']\"):\n",
    "    week.append(i.text)\n",
    "    \n",
    "week = pd.DataFrame(week)\n",
    "week.columns=['week']\n",
    "\n",
    "\n",
    "billiboard=pd.DataFrame({})\n",
    "billiboard['Song Name']=song['song']\n",
    "billiboard['Artist Name']=artist['artist']\n",
    "billiboard['Last Week Rank']=last['last']\n",
    "billiboard[\"Peak Rank\"]=peak['peak']\n",
    "billiboard['Weeks on Board']=week['week']\n",
    "billiboard\n",
    "# Details of top 100 songs on billiboard.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Scrape the details of Data science recruiters from naukri.com.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "recruiters=driver.find_element_by_xpath(\"/html/body/div[1]/div[1]/div/ul[1]/li[2]/a\").get_attribute('href')\n",
    "# Extracting \"Recruiters\" URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(recruiters) #going to \"Recruiters\" URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element_by_xpath(\"/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/div/div[1]/div[1]/div[2]/input\")\n",
    "#keyword search bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.send_keys(\"Data Science\") #enter \"Data Science\" keyword search bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element_by_xpath(\"//button[@class='fl qsbSrch blueBtn']\")\n",
    "search_btn.click() #clicks on search button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "naukriurl=[] #scraping all urls of all recruiters\n",
    "for j in driver.find_elements_by_xpath(\"//div[@class='recImg mid_pImg_Silht']/a\"):\n",
    "            naukriurl.append(j.get_attribute('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recruiters Name</th>\n",
       "      <th>Recruiters Description</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills they hire for</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>Classic ASP Developer , Internet Marketing Professional , Data Science SME , Content Writers , SEO Professional , Revenue Professional</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>.Net , Java , Data Science , Linux Administration , Sql Server Development , Winforms , Wcf Services , Wpf , Telecom Engineering , Technical Management , Software Architecture , Technical Leadership , Solution Architecture ,</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Mid Level, Junior Level</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>, Mean Stack , javascript , angularjs , mongodb , Web Services , rest , express , Node.js , Big Data , iot , Data Science , Cloud Computing , saas , Aws</td>\n",
       "      <td>Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Founder &amp; CEO</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>Hadoop , Spark , Digital Strategy , Data Architecture , Command Center , Cdp , Dmp , Kafka , Data Science , Data Analysis , Big Data Analytics , Real Time Analysis , SQL , Data Warehousing , ETL , Data Modeling , Application Development ,</td>\n",
       "      <td>UK - (london)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abhishek - Only Analytics Hiring - India and APAC</td>\n",
       "      <td>Recruitment - Lead Consultant</td>\n",
       "      <td>Apidel Technologies Division of Transpower</td>\n",
       "      <td>Analytics , Business Intelligence , Business Analytics , Predictive Modeling , Predictive Analytics , Data Science , Data Analysis , Data Analytics , Big Data , Big Data Analytics , Marketing Analytics , Marketing Analysis , Data Mining ,</td>\n",
       "      <td>Vadodara / Baroda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Institute for Financial Management and Research</td>\n",
       "      <td>Programme Manager</td>\n",
       "      <td>IFMR</td>\n",
       "      <td>Analytics &amp; Business Intelligence</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Balu Ramesh</td>\n",
       "      <td>HR Administrator</td>\n",
       "      <td>Techvantage Systems Pvt Ltd</td>\n",
       "      <td>Machine Learning , algorithms , Go Getter , Computer Science , spark , Big Data , hdfs , sql , cassandra , hadoop , python , scala , java , Data Science , Front End , Angularjs , D3.Js , Nodejs , Mean Stack , NoSQL , Scalability ,</td>\n",
       "      <td>Trivandrum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Asif Lucknowi</td>\n",
       "      <td>Director</td>\n",
       "      <td>Weupskill- Live Wire India</td>\n",
       "      <td>-</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>InstaFinancials</td>\n",
       "      <td>Human Resource</td>\n",
       "      <td>CBL Data Science Private Limited</td>\n",
       "      <td>Junior Level, Mid Level</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kalpana Dumpala</td>\n",
       "      <td>Executive Hiring</td>\n",
       "      <td>Innominds Software</td>\n",
       "      <td>Qa , Ui , ux , Java Developer , Java Architect , C++ , qt , Php , Lamp , Api , J2ee , Java , Soa , Esb , Middleware , Bigdata Achitect , Hadoop Architect , Deep Learning , Machine Learning , Data Science , Python , R , Algorithms ,</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mubarak</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MoneyTap</td>\n",
       "      <td>-</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kushal Rastogi</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>QuantMagnum Technologies Pvt. Ltd.</td>\n",
       "      <td>-</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ruchi Dhote</td>\n",
       "      <td>Senior Executive Talent Acquisition</td>\n",
       "      <td>Bristlecone India Ltd</td>\n",
       "      <td>IT Skills</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mahesh Babu Channa</td>\n",
       "      <td>HR Team Lead</td>\n",
       "      <td>SocialPrachar.com</td>\n",
       "      <td>Junior Level, Mid Level</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Kapil Devang</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>BISP Solutions</td>\n",
       "      <td>Big Data , Hadoop , Data Analytics , Data Science</td>\n",
       "      <td>Bhopal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Manisha Yadav</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Easi Tax</td>\n",
       "      <td>Mid Level</td>\n",
       "      <td>Navi Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Riya Rajesh</td>\n",
       "      <td>Manager Talent Acquisition</td>\n",
       "      <td>Novelworx Digital Solutions</td>\n",
       "      <td>IT-Software/Software Services</td>\n",
       "      <td>Cochin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Rashmi Bhattacharjee</td>\n",
       "      <td>HR Head</td>\n",
       "      <td>AXESTRACK SOFTWARE SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>Mid Level, Top Mangement Level</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Faizan Kareem</td>\n",
       "      <td>HR MANAGER</td>\n",
       "      <td>FirstTech Consaltants Pvt.Ltd</td>\n",
       "      <td>Data Analytics , Data Science , Machine Learning , Deep Learning , Nlp , Data Mining , Python , R , Database Administration , Text Mining</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Rithika dadwal</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Affine Analytics</td>\n",
       "      <td>Junior Level, Mid Level</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Azahar Shaikh</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>NEAL ANALYTICS SERVICES PVT LTD</td>\n",
       "      <td>Mid Level, High Level</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sandhya Khandagale</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Compumatrice Multimedia Pvt Ltd</td>\n",
       "      <td>High Level, Mid Level</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Shaun Rao</td>\n",
       "      <td>Manager - Human Resources</td>\n",
       "      <td>Exela Technologies</td>\n",
       "      <td>Java , Net , Angularjs , Hr , Infrastructure , Management , Project Management , Business Analysis , Data Science , Information Technology , Technology</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Manas</td>\n",
       "      <td>Lead Talent acquisition</td>\n",
       "      <td>Autumn Leaf Consulting Services Private Limited</td>\n",
       "      <td>High Level, Top Mangement Level</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>kumar</td>\n",
       "      <td>Proprietor</td>\n",
       "      <td>trainin</td>\n",
       "      <td>Data Science , Hadoop , Rpas , Devops , Python , Aws , Teaching , Big Data</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Sunil Vedula</td>\n",
       "      <td>CEO</td>\n",
       "      <td>Nanoprecise Sci Corp</td>\n",
       "      <td>Signal Processing , Machine Learning , Neural Networks , Data Science , Predictive Analytics , Time Series Analysis , Data Visualization , Technical Leadership , Data Processing , Problem Solving</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Rajat Kumar</td>\n",
       "      <td>Founder &amp; CEO</td>\n",
       "      <td>R.S Consultancy &amp; Services</td>\n",
       "      <td>Web Technologies , Project Management , Software Architecture , Data Science , Object Oriented Programming , Computer Science , Electrical Engineering , Architecture , Technical Leadership , Team Motivation ,</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Priya Khare</td>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>Independent Consultant</td>\n",
       "      <td>-</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Dhruv Dev Dubey</td>\n",
       "      <td>Company Recruitment Head</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>S. Finance Manager , Freshers , Experience , Server Administartion , Vlsi Design Engineer , Fpga , Benchmark Testing , Verilog , Vhdl , Digital Marketing , Market Research , Primary Research , Property Research ,</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Jayanth N</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>Dollarbird Information Services Pvt, Ltd</td>\n",
       "      <td>Data Analytics , Managed Services , Team Leading</td>\n",
       "      <td>Mysoru / Mysore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SREEDHAR</td>\n",
       "      <td>Recruitment Consultant</td>\n",
       "      <td>JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>-</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Radha Manivasagam</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Techcovery</td>\n",
       "      <td>Junior Level</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Prateek Kumar</td>\n",
       "      <td>Head</td>\n",
       "      <td>Trisect</td>\n",
       "      <td>Junior Level</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Amit Sharma</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>ASCO consulting</td>\n",
       "      <td>-</td>\n",
       "      <td>New Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Kanan</td>\n",
       "      <td>senior technology instructor</td>\n",
       "      <td>NY INST</td>\n",
       "      <td>Mid Level, Junior Level</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Shashikant Chaudhary</td>\n",
       "      <td>HR Recruiter/HR Excutive</td>\n",
       "      <td>3D India Staffing Research &amp; Consulting Co. India</td>\n",
       "      <td>-</td>\n",
       "      <td>Aligarh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Brad</td>\n",
       "      <td>Manager, Technical Recruiting</td>\n",
       "      <td>O.C. Tanner</td>\n",
       "      <td>Junior Level, High Level</td>\n",
       "      <td>Salt Lake City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Rutuja Pawar</td>\n",
       "      <td>Technical Recruiter</td>\n",
       "      <td>Demand Matrix</td>\n",
       "      <td>Python , Php , Qa Automation , Ui , Wordpre</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Madhusudhan Sridhar</td>\n",
       "      <td>Erp Implementer</td>\n",
       "      <td>MADHUSUDHAN SRIDHAR</td>\n",
       "      <td>-</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Ankit Sinha</td>\n",
       "      <td>Head-Analytics</td>\n",
       "      <td>Suntech Global</td>\n",
       "      <td>-</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Gaurav Chouhan</td>\n",
       "      <td>Chief Technical Officer</td>\n",
       "      <td>Strategic Consulting Lab</td>\n",
       "      <td>Top Mangement Level, Junior Level</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Rashi Kacker</td>\n",
       "      <td>Sr Product Manager</td>\n",
       "      <td>Impel Labs Pvt. Ltd.</td>\n",
       "      <td>Data Science , Node.js , Angularjs</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Ashwini</td>\n",
       "      <td>Director, Global Delivery</td>\n",
       "      <td>MRP Advisers</td>\n",
       "      <td>-</td>\n",
       "      <td>MYSORE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Balaji Kolli</td>\n",
       "      <td>Co-Founder</td>\n",
       "      <td>Saras Solutions India Pvt Ltd</td>\n",
       "      <td>-</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Rajani Nagaraj</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>WildJasmine</td>\n",
       "      <td>java , hadoop , r , Machine Learning , spark , flume , hdfs , Data Mining , sas , big , Data Science , Cloudera , Impala , Bigdata</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ROHIT Kumar</td>\n",
       "      <td>Architect</td>\n",
       "      <td>LNT Private Limited</td>\n",
       "      <td>Mid Level, High Level</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Amir Chowdhury</td>\n",
       "      <td>Managing Partner</td>\n",
       "      <td>Granular.ai</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Shailja Mishra</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Certybox Pvt.Ltd.</td>\n",
       "      <td>-</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Sunny Sharma</td>\n",
       "      <td>Managing Director - HR</td>\n",
       "      <td>Western Service Providers</td>\n",
       "      <td>Software Professionals , Engineering , Technical Management , Financial Management , Human Resource Management , Banking , Google Adwords , Business Analysis , It Recruitment , Journalism , Content Writing , Machine Learning ,</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Recruiters Name  \\\n",
       "0   Aakash Harit                                        \n",
       "1   shravan Kumar Gaddam                                \n",
       "2   MARSIAN Technologies LLP                            \n",
       "3   Anik Agrawal                                        \n",
       "4   subhas patel                                        \n",
       "5   Abhishek - Only Analytics Hiring - India and APAC   \n",
       "6   Institute for Financial Management and Research     \n",
       "7   Balu Ramesh                                         \n",
       "8   Asif Lucknowi                                       \n",
       "9   InstaFinancials                                     \n",
       "10  Kalpana Dumpala                                     \n",
       "11  Mubarak                                             \n",
       "12  Kushal Rastogi                                      \n",
       "13  Ruchi Dhote                                         \n",
       "14  Mahesh Babu Channa                                  \n",
       "15  Kapil Devang                                        \n",
       "16  Manisha Yadav                                       \n",
       "17  Riya Rajesh                                         \n",
       "18  Rashmi Bhattacharjee                                \n",
       "19  Faizan Kareem                                       \n",
       "20  Rithika dadwal                                      \n",
       "21  Azahar Shaikh                                       \n",
       "22  Sandhya Khandagale                                  \n",
       "23  Shaun Rao                                           \n",
       "24  Manas                                               \n",
       "25  kumar                                               \n",
       "26  Sunil Vedula                                        \n",
       "27  Rajat Kumar                                         \n",
       "28  Priya Khare                                         \n",
       "29  Dhruv Dev Dubey                                     \n",
       "30  Jayanth N                                           \n",
       "31  SREEDHAR                                            \n",
       "32  Radha Manivasagam                                   \n",
       "33  Prateek Kumar                                       \n",
       "34  Amit Sharma                                         \n",
       "35  Kanan                                               \n",
       "36  Shashikant Chaudhary                                \n",
       "37  Brad                                                \n",
       "38  Rutuja Pawar                                        \n",
       "39  Madhusudhan Sridhar                                 \n",
       "40  Ankit Sinha                                         \n",
       "41  Gaurav Chouhan                                      \n",
       "42  Rashi Kacker                                        \n",
       "43  Ashwini                                             \n",
       "44  Balaji Kolli                                        \n",
       "45  Rajani Nagaraj                                      \n",
       "46  ROHIT Kumar                                         \n",
       "47  Amir Chowdhury                                      \n",
       "48  Shailja Mishra                                      \n",
       "49  Sunny Sharma                                        \n",
       "\n",
       "                 Recruiters Description  \\\n",
       "0   HR Manager                            \n",
       "1   Company Recruiter                     \n",
       "2   Company HR                            \n",
       "3   Company Recruiter                     \n",
       "4   Founder & CEO                         \n",
       "5   Recruitment - Lead Consultant         \n",
       "6   Programme Manager                     \n",
       "7   HR Administrator                      \n",
       "8   Director                              \n",
       "9   Human Resource                        \n",
       "10  Executive Hiring                      \n",
       "11  Company HR                            \n",
       "12  Company HR                            \n",
       "13  Senior Executive Talent Acquisition   \n",
       "14  HR Team Lead                          \n",
       "15  HR Manager                            \n",
       "16  HR Executive                          \n",
       "17  Manager Talent Acquisition            \n",
       "18  HR Head                               \n",
       "19  HR MANAGER                            \n",
       "20  HR Recruiter                          \n",
       "21  Company Recruiter                     \n",
       "22  HR Recruiter                          \n",
       "23  Manager - Human Resources             \n",
       "24  Lead Talent acquisition               \n",
       "25  Proprietor                            \n",
       "26  CEO                                   \n",
       "27  Founder & CEO                         \n",
       "28  Senior Manager                        \n",
       "29  Company Recruitment Head              \n",
       "30  Project Manager                       \n",
       "31  Recruitment Consultant                \n",
       "32  HR Executive                          \n",
       "33  Head                                  \n",
       "34  Consultant                            \n",
       "35  senior technology instructor          \n",
       "36  HR Recruiter/HR Excutive              \n",
       "37  Manager, Technical Recruiting         \n",
       "38  Technical Recruiter                   \n",
       "39  Erp Implementer                       \n",
       "40  Head-Analytics                        \n",
       "41  Chief Technical Officer               \n",
       "42  Sr Product Manager                    \n",
       "43  Director, Global Delivery             \n",
       "44  Co-Founder                            \n",
       "45  HR Manager                            \n",
       "46  Architect                             \n",
       "47  Managing Partner                      \n",
       "48  HR Manager                            \n",
       "49  Managing Director - HR                \n",
       "\n",
       "                                              Company  \\\n",
       "0   Data Science Network                                \n",
       "1   Shore Infotech India Pvt. Ltd                       \n",
       "2   MARSIAN Technologies LLP                            \n",
       "3   Enerlytics Software Solutions Pvt Ltd               \n",
       "4   LibraryXProject                                     \n",
       "5   Apidel Technologies Division of Transpower          \n",
       "6   IFMR                                                \n",
       "7   Techvantage Systems Pvt Ltd                         \n",
       "8   Weupskill- Live Wire India                          \n",
       "9   CBL Data Science Private Limited                    \n",
       "10  Innominds Software                                  \n",
       "11  MoneyTap                                            \n",
       "12  QuantMagnum Technologies Pvt. Ltd.                  \n",
       "13  Bristlecone India Ltd                               \n",
       "14  SocialPrachar.com                                   \n",
       "15  BISP Solutions                                      \n",
       "16  Easi Tax                                            \n",
       "17  Novelworx Digital Solutions                         \n",
       "18  AXESTRACK SOFTWARE SOLUTIONS PRIVATE LIMITED        \n",
       "19  FirstTech Consaltants Pvt.Ltd                       \n",
       "20  Affine Analytics                                    \n",
       "21  NEAL ANALYTICS SERVICES PVT LTD                     \n",
       "22  Compumatrice Multimedia Pvt Ltd                     \n",
       "23  Exela Technologies                                  \n",
       "24  Autumn Leaf Consulting Services Private Limited     \n",
       "25  trainin                                             \n",
       "26  Nanoprecise Sci Corp                                \n",
       "27  R.S Consultancy & Services                          \n",
       "28  Independent Consultant                              \n",
       "29  Confidential                                        \n",
       "30  Dollarbird Information Services Pvt, Ltd            \n",
       "31  JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED         \n",
       "32  Techcovery                                          \n",
       "33  Trisect                                             \n",
       "34  ASCO consulting                                     \n",
       "35  NY INST                                             \n",
       "36  3D India Staffing Research & Consulting Co. India   \n",
       "37  O.C. Tanner                                         \n",
       "38  Demand Matrix                                       \n",
       "39  MADHUSUDHAN SRIDHAR                                 \n",
       "40  Suntech Global                                      \n",
       "41  Strategic Consulting Lab                            \n",
       "42  Impel Labs Pvt. Ltd.                                \n",
       "43  MRP Advisers                                        \n",
       "44  Saras Solutions India Pvt Ltd                       \n",
       "45  WildJasmine                                         \n",
       "46  LNT Private Limited                                 \n",
       "47  Granular.ai                                         \n",
       "48  Certybox Pvt.Ltd.                                   \n",
       "49  Western Service Providers                           \n",
       "\n",
       "                                                                                                                                                                                                                              Skills they hire for  \\\n",
       "0   Classic ASP Developer , Internet Marketing Professional , Data Science SME , Content Writers , SEO Professional , Revenue Professional                                                                                                           \n",
       "1   .Net , Java , Data Science , Linux Administration , Sql Server Development , Winforms , Wcf Services , Wpf , Telecom Engineering , Technical Management , Software Architecture , Technical Leadership , Solution Architecture ,                 \n",
       "2   Mid Level, Junior Level                                                                                                                                                                                                                          \n",
       "3   , Mean Stack , javascript , angularjs , mongodb , Web Services , rest , express , Node.js , Big Data , iot , Data Science , Cloud Computing , saas , Aws                                                                                         \n",
       "4   Hadoop , Spark , Digital Strategy , Data Architecture , Command Center , Cdp , Dmp , Kafka , Data Science , Data Analysis , Big Data Analytics , Real Time Analysis , SQL , Data Warehousing , ETL , Data Modeling , Application Development ,   \n",
       "5   Analytics , Business Intelligence , Business Analytics , Predictive Modeling , Predictive Analytics , Data Science , Data Analysis , Data Analytics , Big Data , Big Data Analytics , Marketing Analytics , Marketing Analysis , Data Mining ,   \n",
       "6   Analytics & Business Intelligence                                                                                                                                                                                                                \n",
       "7   Machine Learning , algorithms , Go Getter , Computer Science , spark , Big Data , hdfs , sql , cassandra , hadoop , python , scala , java , Data Science , Front End , Angularjs , D3.Js , Nodejs , Mean Stack , NoSQL , Scalability ,           \n",
       "8   -                                                                                                                                                                                                                                                \n",
       "9   Junior Level, Mid Level                                                                                                                                                                                                                          \n",
       "10  Qa , Ui , ux , Java Developer , Java Architect , C++ , qt , Php , Lamp , Api , J2ee , Java , Soa , Esb , Middleware , Bigdata Achitect , Hadoop Architect , Deep Learning , Machine Learning , Data Science , Python , R , Algorithms ,          \n",
       "11  -                                                                                                                                                                                                                                                \n",
       "12  -                                                                                                                                                                                                                                                \n",
       "13  IT Skills                                                                                                                                                                                                                                        \n",
       "14  Junior Level, Mid Level                                                                                                                                                                                                                          \n",
       "15  Big Data , Hadoop , Data Analytics , Data Science                                                                                                                                                                                                \n",
       "16  Mid Level                                                                                                                                                                                                                                        \n",
       "17  IT-Software/Software Services                                                                                                                                                                                                                    \n",
       "18  Mid Level, Top Mangement Level                                                                                                                                                                                                                   \n",
       "19  Data Analytics , Data Science , Machine Learning , Deep Learning , Nlp , Data Mining , Python , R , Database Administration , Text Mining                                                                                                        \n",
       "20  Junior Level, Mid Level                                                                                                                                                                                                                          \n",
       "21  Mid Level, High Level                                                                                                                                                                                                                            \n",
       "22  High Level, Mid Level                                                                                                                                                                                                                            \n",
       "23  Java , Net , Angularjs , Hr , Infrastructure , Management , Project Management , Business Analysis , Data Science , Information Technology , Technology                                                                                          \n",
       "24  High Level, Top Mangement Level                                                                                                                                                                                                                  \n",
       "25  Data Science , Hadoop , Rpas , Devops , Python , Aws , Teaching , Big Data                                                                                                                                                                       \n",
       "26  Signal Processing , Machine Learning , Neural Networks , Data Science , Predictive Analytics , Time Series Analysis , Data Visualization , Technical Leadership , Data Processing , Problem Solving                                              \n",
       "27  Web Technologies , Project Management , Software Architecture , Data Science , Object Oriented Programming , Computer Science , Electrical Engineering , Architecture , Technical Leadership , Team Motivation ,                                 \n",
       "28  -                                                                                                                                                                                                                                                \n",
       "29  S. Finance Manager , Freshers , Experience , Server Administartion , Vlsi Design Engineer , Fpga , Benchmark Testing , Verilog , Vhdl , Digital Marketing , Market Research , Primary Research , Property Research ,                             \n",
       "30  Data Analytics , Managed Services , Team Leading                                                                                                                                                                                                 \n",
       "31  -                                                                                                                                                                                                                                                \n",
       "32  Junior Level                                                                                                                                                                                                                                     \n",
       "33  Junior Level                                                                                                                                                                                                                                     \n",
       "34  -                                                                                                                                                                                                                                                \n",
       "35  Mid Level, Junior Level                                                                                                                                                                                                                          \n",
       "36  -                                                                                                                                                                                                                                                \n",
       "37  Junior Level, High Level                                                                                                                                                                                                                         \n",
       "38  Python , Php , Qa Automation , Ui , Wordpre                                                                                                                                                                                                      \n",
       "39  -                                                                                                                                                                                                                                                \n",
       "40  -                                                                                                                                                                                                                                                \n",
       "41  Top Mangement Level, Junior Level                                                                                                                                                                                                                \n",
       "42  Data Science , Node.js , Angularjs                                                                                                                                                                                                               \n",
       "43  -                                                                                                                                                                                                                                                \n",
       "44  -                                                                                                                                                                                                                                                \n",
       "45  java , hadoop , r , Machine Learning , spark , flume , hdfs , Data Mining , sas , big , Data Science , Cloudera , Impala , Bigdata                                                                                                               \n",
       "46  Mid Level, High Level                                                                                                                                                                                                                            \n",
       "47  -                                                                                                                                                                                                                                                \n",
       "48  -                                                                                                                                                                                                                                                \n",
       "49  Software Professionals , Engineering , Technical Management , Financial Management , Human Resource Management , Banking , Google Adwords , Business Analysis , It Recruitment , Journalism , Content Writing , Machine Learning ,               \n",
       "\n",
       "                    Location  \n",
       "0   Delhi                     \n",
       "1   Hyderabad / Secunderabad  \n",
       "2   Pune                      \n",
       "3   Ahmedabad                 \n",
       "4   UK - (london)             \n",
       "5   Vadodara / Baroda         \n",
       "6   Chennai                   \n",
       "7   Trivandrum                \n",
       "8   Indore                    \n",
       "9   Bengaluru / Bangalore     \n",
       "10  Hyderabad / Secunderabad  \n",
       "11  Bengaluru / Bangalore     \n",
       "12  Mumbai                    \n",
       "13  Pune                      \n",
       "14  Hyderabad / Secunderabad  \n",
       "15  Bhopal                    \n",
       "16  Navi Mumbai               \n",
       "17  Cochin                    \n",
       "18  Delhi                     \n",
       "19  Hyderabad / Secunderabad  \n",
       "20  Pune                      \n",
       "21  Pune                      \n",
       "22  Pune                      \n",
       "23  Pune                      \n",
       "24  Bengaluru / Bangalore     \n",
       "25  Bengaluru / Bangalore     \n",
       "26  Others                    \n",
       "27  Delhi                     \n",
       "28  Bengaluru / Bangalore     \n",
       "29  Bengaluru / Bangalore     \n",
       "30  Mysoru / Mysore           \n",
       "31  Hyderabad / Secunderabad  \n",
       "32  Bengaluru / Bangalore     \n",
       "33  Noida                     \n",
       "34  New Delhi                 \n",
       "35  Chennai                   \n",
       "36  Aligarh                   \n",
       "37  Salt Lake City            \n",
       "38  Pune                      \n",
       "39  Bengaluru / Bangalore     \n",
       "40  Mumbai                    \n",
       "41  Indore                    \n",
       "42  Bengaluru / Bangalore     \n",
       "43  MYSORE                    \n",
       "44  Hyderabad / Secunderabad  \n",
       "45  Bengaluru / Bangalore     \n",
       "46  Mumbai                    \n",
       "47                            \n",
       "48  Noida                     \n",
       "49  Mumbai                    "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_name=[]\n",
    "rec_desgn=[]\n",
    "company=[]\n",
    "skills=[]\n",
    "location=[]\n",
    "\n",
    "for i in naukriurl:\n",
    "    url=i\n",
    "    driver.get(url)\n",
    "    sleep(4)\n",
    "\n",
    "\n",
    "        \n",
    "# Scraping Name of Data science recruiters from naukri.com.\n",
    "\n",
    "    try:\n",
    "        nm=driver.find_element_by_xpath(\"//h1[@class='fl ellipsis wLimit hd']\")\n",
    "        rec_name.append(nm.text)\n",
    "    except NoSuchElementException:\n",
    "        rec_name.append('-')\n",
    "\n",
    "        \n",
    "# Scraping Designation of Data science recruiters from naukri.com.\n",
    "\n",
    "    try:\n",
    "        ds=driver.find_element_by_xpath(\"//div[@class='ellipsis']\")\n",
    "        rec_desgn.append(ds.text)\n",
    "    except NoSuchElementException:\n",
    "        rec_desgn.append('-')\n",
    "        \n",
    "# Scraping Company of Data science recruiters from naukri.com.\n",
    "        \n",
    "    try:\n",
    "        co=driver.find_element_by_xpath(\"(//a[@class='fl ellipsis widLrg'])[1]\")\n",
    "        company.append(co.text)\n",
    "    except NoSuchElementException:\n",
    "        company.append('-')\n",
    "        \n",
    "        \n",
    "# Scraping Skills they hire for of Data science recruiters from naukri.com.\n",
    "        \n",
    "    try:\n",
    "        sk=driver.find_element_by_xpath(\"//div[@class='fl lPortn']/p\")\n",
    "        skills.append(sk.text)\n",
    "    except NoSuchElementException:\n",
    "        skills.append('-')\n",
    "        \n",
    "        \n",
    "        \n",
    "# Scraping Location of Data science recruiters from naukri.com.\n",
    "        \n",
    "    try:\n",
    "        loc=driver.find_element_by_xpath(\"(//a[@class='fl ellipsis widLrg'])[2]\")\n",
    "        location.append(loc.text)\n",
    "    except NoSuchElementException:\n",
    "        location.append('-')\n",
    "        \n",
    "                        \n",
    "\n",
    "rec_name = pd.DataFrame(rec_name)\n",
    "rec_name.columns=['rec_name']   \n",
    "        \n",
    "rec_desgn = pd.DataFrame(rec_desgn)\n",
    "rec_desgn.columns=['rec_desgn']\n",
    "        \n",
    "company = pd.DataFrame(company)\n",
    "company.columns=['company']        \n",
    "\n",
    "skills = pd.DataFrame(skills)\n",
    "skills.columns=['skills']        \n",
    "\n",
    "location = pd.DataFrame(location)\n",
    "location.columns=['location']        \n",
    "\n",
    "\n",
    "naukri_recruiters=pd.DataFrame({})\n",
    "naukri_recruiters['Recruiters Name']=rec_name['rec_name']\n",
    "naukri_recruiters['Recruiters Description']=rec_desgn['rec_desgn']\n",
    "naukri_recruiters['Company']=company['company']\n",
    "naukri_recruiters[\"Skills they hire for\"]=skills['skills']\n",
    "naukri_recruiters[\"Location\"]=location['location']\n",
    "naukri_recruiters\n",
    "#Details of Data science recruiters from naukri.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Scrape the details of Highest selling novels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book name</th>\n",
       "      <th>Author name</th>\n",
       "      <th>Volumes sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the Love of a Family</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Book name  \\\n",
       "0   Da Vinci Code,The                                               \n",
       "1   Harry Potter and the Deathly Hallows                            \n",
       "2   Harry Potter and the Philosopher's Stone                        \n",
       "3   Harry Potter and the Order of the Phoenix                       \n",
       "4   Fifty Shades of Grey                                            \n",
       "..                   ...                                            \n",
       "95  Ghost,The                                                       \n",
       "96  Happy Days with the Naked Chef                                  \n",
       "97  Hunger Games,The:Hunger Games Trilogy                           \n",
       "98  Lost Boy,The:A Foster Child's Search for the Love of a Family   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours   \n",
       "\n",
       "         Author name Volumes sold        Publisher  \\\n",
       "0   Brown, Dan        5,094,805    Transworld        \n",
       "1   Rowling, J.K.     4,475,152    Bloomsbury        \n",
       "2   Rowling, J.K.     4,200,654    Bloomsbury        \n",
       "3   Rowling, J.K.     4,179,479    Bloomsbury        \n",
       "4   James, E. L.      3,758,936    Random House      \n",
       "..           ...            ...             ...      \n",
       "95  Harris, Robert    807,311      Random House      \n",
       "96  Oliver, Jamie     794,201      Penguin           \n",
       "97  Collins, Suzanne  792,187      Scholastic Ltd.   \n",
       "98  Pelzer, Dave      791,507      Orion             \n",
       "99  Oliver, Jamie     791,095      Penguin           \n",
       "\n",
       "                          Genre  \n",
       "0   Crime, Thriller & Adventure  \n",
       "1   Children's Fiction           \n",
       "2   Children's Fiction           \n",
       "3   Children's Fiction           \n",
       "4   Romance & Sagas              \n",
       "..              ...              \n",
       "95  General & Literary Fiction   \n",
       "96  Food & Drink: General        \n",
       "97  Young Adult Fiction          \n",
       "98  Biography: General           \n",
       "99  Food & Drink: General        \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping Author name of Highest selling novel\n",
    "\n",
    "bookname=[]\n",
    "for i in driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[2]\"):\n",
    "    bookname.append(i.text)\n",
    "    \n",
    "bookname = pd.DataFrame(bookname)\n",
    "bookname.columns=['bookname']\n",
    "\n",
    "#scraping Author name of Highest selling novel\n",
    "\n",
    "authorname=[]\n",
    "for i in driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[3]\"):\n",
    "    authorname.append(i.text)\n",
    "    \n",
    "authorname = pd.DataFrame(authorname)\n",
    "authorname.columns=['authorname']\n",
    "\n",
    "\n",
    "#scraping Volumes sold of Highest selling novel\n",
    "\n",
    "volume=[]\n",
    "for i in driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[4]\"):\n",
    "    volume.append(i.text)\n",
    "    \n",
    "volume = pd.DataFrame(volume)\n",
    "volume.columns=['volume']\n",
    "\n",
    "\n",
    "#scraping Publisher of Highest selling novel\n",
    "\n",
    "publisher=[]\n",
    "for i in driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[5]\"):\n",
    "    publisher.append(i.text)\n",
    "    \n",
    "publisher = pd.DataFrame(publisher)\n",
    "publisher.columns=['publisher']\n",
    "\n",
    "\n",
    "#scraping Genre of Highest selling novel\n",
    "\n",
    "genre=[]\n",
    "for i in driver.find_elements_by_xpath(\"//table[@class='in-article sortable']/tbody/tr/td[6]\"):\n",
    "    genre.append(i.text)\n",
    "    \n",
    "genre = pd.DataFrame(genre)\n",
    "genre.columns=['genre']\n",
    "\n",
    "\n",
    "highest_selling_novels=pd.DataFrame({})\n",
    "highest_selling_novels['Book name']=bookname['bookname']\n",
    "highest_selling_novels['Author name']=authorname['authorname']\n",
    "highest_selling_novels['Volumes sold']=volume['volume']\n",
    "highest_selling_novels[\"Publisher\"]=publisher['publisher']\n",
    "highest_selling_novels[\"Genre\"]=genre['genre']\n",
    "highest_selling_novels\n",
    "# Details of Highest selling novels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Scrape the details most watched tv series of all time from imdb.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.imdb.com/list/ls095964455/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1,823,069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>863,720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>874,445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>262,673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>224,011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>44,575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>55,064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8</td>\n",
       "      <td>167,707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>34,879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>191,397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0   Game of Thrones                 (2011–2019)  Action, Adventure, Drama   \n",
       "1   Stranger Things                 (2016– )     Drama, Fantasy, Horror     \n",
       "2   The Walking Dead                (2010–2022)  Drama, Horror, Thriller    \n",
       "3   13 Reasons Why                  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4   The 100                         (2014–2020)  Drama, Mystery, Sci-Fi     \n",
       "..      ...                                 ...                     ...     \n",
       "95  Reign                           (2013–2017)  Drama, Fantasy             \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97  Criminal Minds                  (2005–2020)  Crime, Drama, Mystery      \n",
       "98  Scream: The TV Series           (2015–2019)  Comedy, Crime, Drama       \n",
       "99  The Haunting of Hill House      (2018)       Drama, Horror, Mystery     \n",
       "\n",
       "   Run time Ratings      Votes  \n",
       "0   57 min   9.3     1,823,069  \n",
       "1   51 min   8.7     863,720    \n",
       "2   44 min   8.2     874,445    \n",
       "3   60 min   7.6     262,673    \n",
       "4   43 min   7.6     224,011    \n",
       "..     ...   ...         ...    \n",
       "95  42 min   7.5     44,575     \n",
       "96  50 min   7.8     55,064     \n",
       "97  42 min   8       167,707    \n",
       "98  45 min   7.1     34,879     \n",
       "99  572 min  8.6     191,397    \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping name of most watched tv series of all time from imdb.com\n",
    "\n",
    "shwname=[]\n",
    "for i in driver.find_elements_by_xpath(\"//h3[@class='lister-item-header']/a\"):\n",
    "    shwname.append(i.text)\n",
    "    \n",
    "shwname = pd.DataFrame(shwname)\n",
    "shwname.columns=['shwname']\n",
    "\n",
    "\n",
    "#scraping Year span of most watched tv series of all time from imdb.com\n",
    "\n",
    "shwyear=[]\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='lister-item-year text-muted unbold']\"):\n",
    "    shwyear.append(i.text)\n",
    "    \n",
    "shwyear = pd.DataFrame(shwyear)\n",
    "shwyear.columns=['shwyear']\n",
    "\n",
    "\n",
    "#scraping Genre of most watched tv series of all time from imdb.com\n",
    "\n",
    "shwgenre=[]\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='genre']\"):\n",
    "    shwgenre.append(i.text)\n",
    "    \n",
    "shwgenre = pd.DataFrame(shwgenre)\n",
    "shwgenre.columns=['shwgenre']\n",
    "\n",
    "\n",
    "#scraping Run time of most watched tv series of all time from imdb.com\n",
    "\n",
    "run_time=[]\n",
    "for i in driver.find_elements_by_xpath(\"//span[@class='runtime']\"):\n",
    "    run_time.append(i.text)\n",
    "    \n",
    "run_time = pd.DataFrame(run_time)\n",
    "run_time.columns=['run_time']\n",
    "\n",
    "\n",
    "#scraping Ratings of most watched tv series of all time from imdb.com\n",
    "\n",
    "ratings=[]\n",
    "for i in driver.find_elements_by_xpath(\"//div[@class='ipl-rating-star small']/span[2]\"):\n",
    "    ratings.append(i.text)\n",
    "    \n",
    "ratings = pd.DataFrame(ratings)\n",
    "ratings.columns=['ratings']\n",
    "\n",
    "#scraping Votes of most watched tv series of all time from imdb.com\n",
    "\n",
    "vote=[]\n",
    "for i in driver.find_elements_by_xpath(\"//span[@name='nv']\"):\n",
    "    vote.append(i.text)\n",
    "    \n",
    "vote = pd.DataFrame(vote)\n",
    "vote.columns=['vote']\n",
    "\n",
    "\n",
    "\n",
    "Top_100_most_watched_tv_shows=pd.DataFrame({})\n",
    "Top_100_most_watched_tv_shows['Name']=shwname['shwname']\n",
    "Top_100_most_watched_tv_shows['Year Span']=shwyear['shwyear']\n",
    "Top_100_most_watched_tv_shows['Genre']=shwgenre['shwgenre']\n",
    "Top_100_most_watched_tv_shows['Run time']=run_time['run_time']\n",
    "Top_100_most_watched_tv_shows[\"Ratings\"]=ratings['ratings']\n",
    "Top_100_most_watched_tv_shows[\"Votes\"]=vote['vote']\n",
    "Top_100_most_watched_tv_shows\n",
    "# Details of most watched tv series of all time from imdb.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://archive.ics.uci.edu/ml/index.php'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldataset=driver.find_element_by_xpath(\"/html/body/table[1]/tbody/tr/td[2]/span[2]/a\").get_attribute('href')\n",
    "# Extracting \"View ALL Data Sets\" URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(alldataset) #going to \"View ALL Data Sets\" URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataurl=[] #scraping all urls of all datasets\n",
    "for j in driver.find_elements_by_xpath(\"//p[@class='normal']/b/a\"):\n",
    "    dataurl.append(j.get_attribute('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datasetname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>in-vehicle coupon recommendation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>Gait Classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>Synchronous Machine Data Set</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          datasetname\n",
       "0    Abalone                         \n",
       "1    Adult                           \n",
       "2    Annealing                       \n",
       "3    Anonymous Microsoft Web Data    \n",
       "4    Arrhythmia                      \n",
       "..          ...                      \n",
       "583  in-vehicle coupon recommendation\n",
       "584  Gait Classification             \n",
       "585  Wikipedia Math Essentials       \n",
       "586  Wikipedia Math Essentials       \n",
       "587  Synchronous Machine Data Set    \n",
       "\n",
       "[588 rows x 1 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Dataset name of Datasets from UCI machine learning repositories.\n",
    "\n",
    "datasetname=[]\n",
    "for i in driver.find_elements_by_xpath(\"//p[@class='normal']/b/a\"):\n",
    "    datasetname.append(i.text)\n",
    "    \n",
    "datasetname = pd.DataFrame(datasetname)\n",
    "datasetname.columns=['datasetname']\n",
    "datasetname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Table View  List View</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abalone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multivariate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Multivariate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>Time-Series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>Time-Series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>Synchronous Machine Data Set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>Multivariate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1177 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          datatype\n",
       "0     Table View  List View       \n",
       "1     Abalone                     \n",
       "2     Multivariate                \n",
       "3     Adult                       \n",
       "4     Multivariate                \n",
       "...             ...               \n",
       "1172  Time-Series                 \n",
       "1173  Wikipedia Math Essentials   \n",
       "1174  Time-Series                 \n",
       "1175  Synchronous Machine Data Set\n",
       "1176  Multivariate                \n",
       "\n",
       "[1177 rows x 1 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping Data types of Datasets from UCI machine learning repositories.\n",
    "\n",
    "datatype=[]\n",
    "for i in driver.find_elements_by_xpath(\"//td[2]/p[@class='normal']\"):\n",
    "    datatype.append(i.text)\n",
    "    \n",
    "datatype = pd.DataFrame(datatype)\n",
    "datatype.columns=['datatype']\n",
    "datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype=datatype.iloc[range(0,len(datatype),2)]\n",
    " # we can see the data what is present in the odd rows is the data we need. so extracting odd rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype = datatype[1:] # we can delete the first row as it is not relevant to the data we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatype=datatype.reset_index(drop=True)  #resetting index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multivariate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multivariate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multivariate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Multivariate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>Multivariate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>Multivariate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>Time-Series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>Time-Series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>Multivariate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          datatype\n",
       "0    Multivariate \n",
       "1    Multivariate \n",
       "2    Multivariate \n",
       "3                 \n",
       "4    Multivariate \n",
       "..             ...\n",
       "583  Multivariate \n",
       "584  Multivariate \n",
       "585  Time-Series  \n",
       "586  Time-Series  \n",
       "587  Multivariate \n",
       "\n",
       "[588 rows x 1 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No of Instances</th>\n",
       "      <th>No of Attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>in-vehicle coupon recommendation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>12684</td>\n",
       "      <td>23</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>Gait Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>48</td>\n",
       "      <td>321</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>Synchronous Machine Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>557</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Dataset Name      Data Type                  Task  \\\n",
       "0    Abalone                           Multivariate   Classification         \n",
       "1    Adult                             Multivariate   Classification         \n",
       "2    Annealing                         Multivariate   Classification         \n",
       "3    Anonymous Microsoft Web Data                     Recommender-Systems    \n",
       "4    Arrhythmia                        Multivariate   Classification         \n",
       "..          ...                                  ...              ...        \n",
       "583  in-vehicle coupon recommendation  Multivariate   Classification         \n",
       "584  Gait Classification               Multivariate   Classification         \n",
       "585  Wikipedia Math Essentials         Time-Series    Regression             \n",
       "586  Wikipedia Math Essentials         Time-Series    Regression             \n",
       "587  Synchronous Machine Data Set      Multivariate   Regression             \n",
       "\n",
       "                  Attribute Type No of Instances No of Attributes   Year  \n",
       "0    Categorical, Integer, Real   4177            8                1995   \n",
       "1    Categorical, Integer         48842           14               1996   \n",
       "2    Categorical, Integer, Real   798             38                      \n",
       "3    Categorical                  37711           294              1998   \n",
       "4    Categorical, Integer, Real   452             279              1998   \n",
       "..                           ...   ...             ...               ...  \n",
       "583                               12684           23               2020   \n",
       "584  Real                         48              321              2020   \n",
       "585  Real                         731             1068             2021   \n",
       "586  Real                         731             1068             2021   \n",
       "587  Real                         557             5                2021   \n",
       "\n",
       "[588 rows x 7 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scraping by going into each url- alternate method\n",
    "task=[]\n",
    "attributetype=[]\n",
    "instances=[]\n",
    "attribute=[]\n",
    "year=[]\n",
    "\n",
    "\n",
    "# Scraping Task of Datasets from UCI machine learning repositories.\n",
    "\n",
    "task=[]\n",
    "for i in driver.find_elements_by_xpath(\"//td[3]/p[@class='normal']\"):\n",
    "    task.append(i.text)\n",
    "    \n",
    "task = pd.DataFrame(task)\n",
    "task.columns=['task']\n",
    "\n",
    "\n",
    "# Scraping Attribute types of Datasets from UCI machine learning repositories.\n",
    "\n",
    "attributetype=[]\n",
    "for i in driver.find_elements_by_xpath(\"//td[4]/p[@class='normal']\"):\n",
    "    attributetype.append(i.text)\n",
    "    \n",
    "attributetype = pd.DataFrame(attributetype)\n",
    "attributetype.columns=['attributetype']\n",
    "\n",
    "\n",
    "# Scraping No of instances of Datasets from UCI machine learning repositories.\n",
    "\n",
    "instances=[]\n",
    "for i in driver.find_elements_by_xpath(\"//td[5]/p[@class='normal']\"):\n",
    "    instances.append(i.text)\n",
    "    \n",
    "instances = pd.DataFrame(instances)\n",
    "instances.columns=['instances']\n",
    "\n",
    "\n",
    "# Scraping No of attribute of Datasets from UCI machine learning repositories.\n",
    "\n",
    "attribute=[]\n",
    "for i in driver.find_elements_by_xpath(\"//td[6]/p[@class='normal']\"):\n",
    "    attribute.append(i.text)\n",
    "    \n",
    "attribute = pd.DataFrame(attribute)\n",
    "attribute.columns=['attribute']\n",
    "\n",
    "\n",
    "# Scraping Year of Datasets from UCI machine learning repositories.\n",
    "\n",
    "year=[]\n",
    "for i in driver.find_elements_by_xpath(\"//td[7]/p[@class='normal']\"):\n",
    "    year.append(i.text)\n",
    "    \n",
    "year = pd.DataFrame(year)\n",
    "year.columns=['year']\n",
    "\n",
    "\n",
    "\n",
    "datasets=pd.DataFrame({})\n",
    "datasets['Dataset Name']=datasetname['datasetname']\n",
    "datasets['Data Type']=datatype['datatype']\n",
    "datasets['Task']=task['task']\n",
    "datasets[\"Attribute Type\"]=attributetype['attributetype']\n",
    "datasets[\"No of Instances\"]=instances['instances']\n",
    "datasets[\"No of Attributes\"]=attribute['attribute']\n",
    "datasets[\"Year\"]=year['year']\n",
    "datasets\n",
    "# Details of Datasets from UCI machine learning repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No of Instances</th>\n",
       "      <th>No of Attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>-</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>-</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>-</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td>N/A</td>\n",
       "      <td>-</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>-</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>in-vehicle coupon recommendation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>-</td>\n",
       "      <td>N/A</td>\n",
       "      <td>12684</td>\n",
       "      <td>23</td>\n",
       "      <td>2020-09-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>Gait Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>48</td>\n",
       "      <td>321</td>\n",
       "      <td>2020-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021-04-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021-04-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>Synchronous Machine Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>-</td>\n",
       "      <td>Real</td>\n",
       "      <td>557</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-04-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Dataset Name     Data Type Task  \\\n",
       "0    Abalone                           Multivariate  -     \n",
       "1    Adult                             Multivariate  -     \n",
       "2    Annealing                         Multivariate  -     \n",
       "3    Anonymous Microsoft Web Data      N/A           -     \n",
       "4    Arrhythmia                        Multivariate  -     \n",
       "..          ...                                 ... ..     \n",
       "583  in-vehicle coupon recommendation  Multivariate  -     \n",
       "584  Gait Classification               Multivariate  -     \n",
       "585  Wikipedia Math Essentials         Time-Series   -     \n",
       "586  Wikipedia Math Essentials         Time-Series   -     \n",
       "587  Synchronous Machine Data Set      Multivariate  -     \n",
       "\n",
       "                 Attribute Type No of Instances No of Attributes        Year  \n",
       "0    Categorical, Integer, Real  4177            8                1995-12-01  \n",
       "1    Categorical, Integer        48842           14               1996-05-01  \n",
       "2    Categorical, Integer, Real  798             38               N/A         \n",
       "3    Categorical                 37711           294              1998-11-01  \n",
       "4    Categorical, Integer, Real  452             279              1998-01-01  \n",
       "..                          ...  ...             ...                     ...  \n",
       "583  N/A                         12684           23               2020-09-15  \n",
       "584  Real                        48              321              2020-10-14  \n",
       "585  Real                        731             1068             2021-04-20  \n",
       "586  Real                        731             1068             2021-04-20  \n",
       "587  Real                        557             5                2021-04-21  \n",
       "\n",
       "[588 rows x 7 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Datatype=[]\n",
    "Task=[]\n",
    "Attributetype=[]\n",
    "Instances=[]\n",
    "Attribute=[]\n",
    "Year=[]\n",
    "\n",
    "for i in dataurl:\n",
    "    url=i\n",
    "    driver.get(url)\n",
    "    sleep(4)\n",
    "\n",
    "        \n",
    "# Scraping Data types of Datasets from UCI machine learning repositories.\n",
    "\n",
    "    try:\n",
    "        dt=driver.find_element_by_xpath(\"/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[1]/td[2]/p\")\n",
    "        Datatype.append(dt.text)\n",
    "    except NoSuchElementException:\n",
    "        Datatype.append('-')\n",
    "        \n",
    "# Scraping Task of Datasets from UCI machine learning repositories.\n",
    "        \n",
    "    try:\n",
    "        ta=driver.find_element_by_xpath(\"(/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[3]/td[2]/p\")\n",
    "        Task.append(ta.text)\n",
    "    except NoSuchElementException:\n",
    "        Task.append('-')\n",
    "        \n",
    "        \n",
    "# Scraping Attribute types of Datasets from UCI machine learning repositories.\n",
    "        \n",
    "    try:\n",
    "        att=driver.find_element_by_xpath(\"/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[2]/td[2]/p\")\n",
    "        Attributetype.append(att.text)\n",
    "    except NoSuchElementException:\n",
    "        Attributetype.append('-')\n",
    "        \n",
    "        \n",
    "        \n",
    "# Scraping No of instances of Datasets from UCI machine learning repositories.\n",
    "        \n",
    "    try:\n",
    "        inst=driver.find_element_by_xpath(\"/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[1]/td[4]/p\")\n",
    "        Instances.append(inst.text)\n",
    "    except NoSuchElementException:\n",
    "        Instances.append('-')\n",
    "        \n",
    "\n",
    "# Scraping No of attribute of Datasets from UCI machine learning repositories.\n",
    "        \n",
    "    try:\n",
    "        at=driver.find_element_by_xpath(\"/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[2]/td[4]/p\")\n",
    "        Attribute.append(at.text)\n",
    "    except NoSuchElementException:\n",
    "        Attribute.append('-')\n",
    "\n",
    "# Scraping Year of Datasets from UCI machine learning repositories.\n",
    "        \n",
    "    try:\n",
    "        yr=driver.find_element_by_xpath(\"/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[2]/td[6]/p\")\n",
    "        Year.append(yr.text)\n",
    "    except NoSuchElementException:\n",
    "        Year.append('-')\n",
    "        \n",
    "\n",
    "\n",
    "Datatype = pd.DataFrame(Datatype)\n",
    "Datatype.columns=['datatype']\n",
    "        \n",
    "Task = pd.DataFrame(Task)\n",
    "Task.columns=['task']        \n",
    "\n",
    "Attributetype = pd.DataFrame(Attributetype)\n",
    "Attributetype.columns=['attributetype']        \n",
    "\n",
    "Instances = pd.DataFrame(Instances)\n",
    "Instances.columns=['instances']        \n",
    "\n",
    "Attribute = pd.DataFrame(Attribute)\n",
    "Attribute.columns=['attribute'] \n",
    "\n",
    "Year = pd.DataFrame(Year)\n",
    "Year.columns=['year'] \n",
    "\n",
    "Datasets=pd.DataFrame({})\n",
    "Datasets['Dataset Name']=datasetname['datasetname']\n",
    "Datasets['Data Type']=Datatype['datatype']\n",
    "Datasets['Task']=Task['task']\n",
    "Datasets[\"Attribute Type\"]=Attributetype['attributetype']\n",
    "Datasets[\"No of Instances\"]=Instances['instances']\n",
    "Datasets[\"No of Attributes\"]=Attribute['attribute']\n",
    "Datasets[\"Year\"]=Year['year']\n",
    "Datasets\n",
    "# Details of Datasets from UCI machine learning repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
